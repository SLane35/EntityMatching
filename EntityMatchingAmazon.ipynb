{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"EntityMatchingAmazon.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.3"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"aXpIRSAQ-cw1"},"source":["# Getting started with DeepMatcher\n","\n","Note: you can run **[this notebook live in Google Colab](https://colab.research.google.com/github/anhaidgroup/deepmatcher/blob/master/examples/getting_started.ipynb)** and use free GPUs provided by Google.\n","\n","This tutorial describes how to effortlessly perform entity matching using deep neural networks. Specifically, we will see how to match pairs of tuples (also called data records or table rows) to determine if they refer to the same real world entity. To do so, we will need labeled examples as input, i.e., tuple pairs which have been annotated as matches or non-matches. This will be used to train our neural network using supervised learning. At the end of this tutorial, you will have a trained neural network as output which you can easily apply to unlabeled tuple pairs to make predictions."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"19SozaN8QJOf"},"source":["As an overview, here are the 4 steps to use `deepmatcher` which we will go through in this tutorial:\n","\n","<ol start=\"0\">\n","  <li>Setup</li>\n","  <li>Process labeled data</li>\n","  <li>Define neural network model</li>\n","  <li>Train model</li>\n","  <li>Apply model to new data</li>\n","</ol>\n","\n","Let's begin!"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"sBtZVvrSQJOf"},"source":["## Step 0. Setup\n","\n","If you are running this notebook inside Colab, you will first need to install necessary packages by running the code below:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"LEiDiDNz-PEG","colab":{"base_uri":"https://localhost:8080/","height":136},"executionInfo":{"status":"ok","timestamp":1599596461976,"user_tz":-120,"elapsed":31550,"user":{"displayName":"Zoé Goey","photoUrl":"","userId":"18241306402691044040"}},"outputId":"4f3ccd0c-8b69-4eb8-bd58-a0b92acc5392"},"source":["try:\n","    import deepmatcher\n","except:\n","    !pip install -qqq deepmatcher"],"execution_count":1,"outputs":[{"output_type":"stream","text":["\u001b[K     |████████████████████████████████| 51kB 2.5MB/s \n","\u001b[K     |████████████████████████████████| 51kB 7.1MB/s \n","\u001b[K     |████████████████████████████████| 296kB 14.6MB/s \n","\u001b[?25h  Building wheel for deepmatcher (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for fasttextmirror (setup.py) ... \u001b[?25lerror\n","\u001b[31m  ERROR: Failed building wheel for fasttextmirror\u001b[0m\n","\u001b[?25h    Running setup.py install for fasttextmirror ... \u001b[?25l\u001b[?25hdone\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"D1Hmd9LXQJOk"},"source":["Now let's import `deepmatcher` which will do all the heavy lifting to build and train neural network models for entity matching. "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"0422OsKBQJOk","colab":{},"executionInfo":{"status":"ok","timestamp":1599596474064,"user_tz":-120,"elapsed":4881,"user":{"displayName":"Zoé Goey","photoUrl":"","userId":"18241306402691044040"}}},"source":["import deepmatcher as dm"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"g6inOGkQQJOn"},"source":["We recommend having a GPU available for the training in Step 4. In case a GPU is not available, we will use all available CPU cores. You can run the following command to determine if a GPU is available and will be used for training:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"GYb5r0etQJOo","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1599596479885,"user_tz":-120,"elapsed":599,"user":{"displayName":"Zoé Goey","photoUrl":"","userId":"18241306402691044040"}},"outputId":"5de9d935-164b-4415-b2a1-8d4b3f97af03"},"source":["import torch\n","torch.cuda.is_available()"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Dv_sFh1_QJOs"},"source":["### Download sample data for entity matching\n","\n","Now let's get some sample data to play with in this tutorial. We will need three sets of labeled data and one set of unlabeled data:\n","\n","1. **Training Data:** This is used for training our neural network model.\n","2. **Validation Data:** This is used for determining the configuration (i.e., hyperparameters) of our model in such a way that the model does not overfit to the training set.\n","3. **Test Data:** This is used to estimate the performance of our trained model on unlabeled data.\n","4. **Unlabeled Data:** The trained model is applied on this data to obtain predictions, which can then be used for downstream tasks in practical application scenarios.\n","\n","We download these four data sets to the `sample_data` directory:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"gvPSNrnUuHNF","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1599599056470,"user_tz":-120,"elapsed":2519,"user":{"displayName":"Zoé Goey","photoUrl":"","userId":"18241306402691044040"}},"outputId":"7fd59f71-e063-42e0-c88e-6b67892a3229"},"source":["!mkdir sample_data\n","!mkdir \"sample_data/itunes-amazon\"\n","!wget --no-check-certificate -qnc -P sample_data/itunes-amazon https://raw.githubusercontent.com/anhaidgroup/deepmatcher/master/examples/sample_data/itunes-amazon/train.csv\n","!wget --no-check-certificate -qnc -P sample_data/itunes-amazon https://raw.githubusercontent.com/anhaidgroup/deepmatcher/master/examples/sample_data/itunes-amazon/validation.csv\n","!wget --no-check-certificate -qnc -P sample_data/itunes-amazon https://raw.githubusercontent.com/anhaidgroup/deepmatcher/master/examples/sample_data/itunes-amazon/test.csv\n","!wget --no-check-certificate -qnc -P sample_data/itunes-amazon https://raw.githubusercontent.com/anhaidgroup/deepmatcher/master/examples/sample_data/itunes-amazon/unlabeled.csv"],"execution_count":27,"outputs":[{"output_type":"stream","text":["mkdir: cannot create directory ‘sample_data’: File exists\n","mkdir: cannot create directory ‘sample_data/itunes-amazon’: File exists\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"lu6QgmbDQJOv"},"source":["To get an idea of how our data looks like, let's take a peek at the training dataset:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"lpsH6NEZQJOw","colab":{"base_uri":"https://localhost:8080/","height":479},"executionInfo":{"status":"ok","timestamp":1599596540258,"user_tz":-120,"elapsed":626,"user":{"displayName":"Zoé Goey","photoUrl":"","userId":"18241306402691044040"}},"outputId":"59e046fd-9a5e-45ed-f8b2-cf1e952f1a32"},"source":["import pandas as pd\n","pd.read_csv('sample_data/itunes-amazon/train.csv').head()"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>label</th>\n","      <th>left_Song_Name</th>\n","      <th>left_Artist_Name</th>\n","      <th>left_Album_Name</th>\n","      <th>left_Genre</th>\n","      <th>left_Price</th>\n","      <th>left_CopyRight</th>\n","      <th>left_Time</th>\n","      <th>left_Released</th>\n","      <th>right_Song_Name</th>\n","      <th>right_Artist_Name</th>\n","      <th>right_Album_Name</th>\n","      <th>right_Genre</th>\n","      <th>right_Price</th>\n","      <th>right_CopyRight</th>\n","      <th>right_Time</th>\n","      <th>right_Released</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>448</td>\n","      <td>0</td>\n","      <td>Baby When the Light ( David Guetta &amp; Fred Rist...</td>\n","      <td>David Guetta</td>\n","      <td>Pop Life ( Extended Version ) [ Bonus Version ]</td>\n","      <td>Dance , Music , Rock , Pop , House , Electroni...</td>\n","      <td>$ 1.29</td>\n","      <td>‰ ãÑ 2007 Gum Records</td>\n","      <td>6:17</td>\n","      <td>18-Sep-07</td>\n","      <td>Revolver ( Madonna Vs. David Guetta Feat . Lil...</td>\n","      <td>David Guetta</td>\n","      <td>One Love ( Deluxe Version )</td>\n","      <td>Dance &amp; Electronic</td>\n","      <td>$ 1.29</td>\n","      <td>( C ) 2014 Swedish House Mafia Holdings Ltd ( ...</td>\n","      <td>3:18</td>\n","      <td>August 21 , 2009</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>287</td>\n","      <td>1</td>\n","      <td>Outversion</td>\n","      <td>Mark Ronson</td>\n","      <td>Version</td>\n","      <td>Pop , Music , R&amp;B / Soul,Soul,Dance,Rock,Jazz,...</td>\n","      <td>$ 0.99</td>\n","      <td>2007 Mark Ronson under exclusive license to SO...</td>\n","      <td>1:50</td>\n","      <td>10-Jul-07</td>\n","      <td>Outversion</td>\n","      <td>Mark Ronson</td>\n","      <td>Version [ Explicit ]</td>\n","      <td>Pop</td>\n","      <td>$ 0.99</td>\n","      <td>( c ) 2011 J'adore Records</td>\n","      <td>1:50</td>\n","      <td>July 10 , 2007</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>534</td>\n","      <td>0</td>\n","      <td>Peer Pressure ( feat . Traci Nelson )</td>\n","      <td>Snoop Dogg</td>\n","      <td>Doggumentary</td>\n","      <td>Hip-Hop/Rap , Music , Rock , Gangsta Rap , Wes...</td>\n","      <td>$ 1.29</td>\n","      <td>‰ ãÑ 2011 Capitol Records , LLC . All rights r...</td>\n","      <td>4:07</td>\n","      <td>29-Mar-11</td>\n","      <td>Boom ( ( Feat . T-Pain ) [ Edited ] )</td>\n","      <td>Snoop Dogg</td>\n","      <td>Doggumentary [ Edited ]</td>\n","      <td>Rap &amp; Hip-Hop , West Coast</td>\n","      <td>$ 1.29</td>\n","      <td>( C ) 2011 Capitol Records , LLC</td>\n","      <td>3:50</td>\n","      <td>March 29 , 2011</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>181</td>\n","      <td>1</td>\n","      <td>Stars Come Out ( Tim Mason Remix )</td>\n","      <td>Zedd</td>\n","      <td>Stars Come Out ( Remixes ) - EP</td>\n","      <td>Dance , Music , Electronic , House</td>\n","      <td>$ 1.29</td>\n","      <td>2012 Dim Mak Inc.</td>\n","      <td>5:49</td>\n","      <td>20-May-14</td>\n","      <td>Stars Come Out ( Dillon Francis Remix )</td>\n","      <td>Zedd</td>\n","      <td>Stars Come Out [ Dillon Francis Remix ]</td>\n","      <td>Dance &amp; Electronic</td>\n","      <td>$ 1.29</td>\n","      <td>2012 Dim Mak Inc.</td>\n","      <td>4:08</td>\n","      <td>May 20 , 2014</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>485</td>\n","      <td>0</td>\n","      <td>Jump ( feat . Nelly Furtado )</td>\n","      <td>Flo Rida</td>\n","      <td>R.O.O.T.S. ( Deluxe Version )</td>\n","      <td>Hip-Hop/Rap , Music</td>\n","      <td>$ 1.29</td>\n","      <td>‰ ãÑ 2009 Atlantic Recording Corporation for t...</td>\n","      <td>3:28</td>\n","      <td>30-Mar-09</td>\n","      <td>Yayo [ Feat . Brisco , Billy Blue , Ball Greez...</td>\n","      <td>Flo Rida</td>\n","      <td>R.O.O.T.S. ( Route Of Overcoming The Struggle ...</td>\n","      <td>Rap &amp; Hip-Hop</td>\n","      <td>$ 1.29</td>\n","      <td>( C ) 2012 Motown Records , a Division of UMG ...</td>\n","      <td>7:53</td>\n","      <td>March 30 , 2009</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    id  label  ... right_Time    right_Released\n","0  448      0  ...       3:18  August 21 , 2009\n","1  287      1  ...       1:50    July 10 , 2007\n","2  534      0  ...       3:50   March 29 , 2011\n","3  181      1  ...       4:08     May 20 , 2014\n","4  485      0  ...       7:53   March 30 , 2009\n","\n","[5 rows x 18 columns]"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"KuCrlwjeQs8i"},"source":["## Step 1. Process labeled data\n","\n","Before we can use our data for training, `deepmatcher` needs to first load and process it in order to prepare it for neural network training. Currently `deepmatcher` only supports processing CSV files. Each CSV file is assumed to have the following kinds of columns:\n","\n","* **\"Left\" attributes (required):** Our goal is to match tuple pairs. \"Left\" attributes are columns that correspond to the \"left\" tuple or the first tuple in the tuple pair. These column names are expected to be prefixed with \"left_\" by default.\n","* **\"Right\" attributes (required):** \"Right\" attributes are columns that correspond to the \"right\" tuple or the second tuple in the tuple pair. These column names are expected to be prefixed with \"right_\" by default.\n","* **Label column (required for train, validation, test):** Column containing the labels (match or non-match) for each tuple pair. Expected to be named \"label\" by default\n","* **ID column (required):** Column containing a unique ID for each tuple pair. This is for evaluation convenience.  Expected to be named \"id\" by default.\n","\n","More details on what data processing involves and ways to customize it are described in **[this notebook](https://nbviewer.jupyter.org/github/anhaidgroup/deepmatcher/blob/master/examples/data_processing.ipynb)**. \n","\n","### Processing labeled data\n","In order to process our train, validation and test CSV files we call `dm.data.process` in the following code snippet which will load and process the CSV files and return three processed `MatchingDataset` objects respectively. These dataset objects will later be used for training and evaluation. The basic parameters to `dm.data.process` are as follows:\n","\n","* **path (required): ** The path where all data is stored. This includes train, validation and test. `deepmatcher` may create new files in this directory to store information about these data sets. This allows subsequent `dm.data.process` calls to be much faster.\n","* **train (required): ** File name of training data in `path` directory.\n","* **validation (required): ** File name of validation data in `path` directory.\n","* **test (optional): ** File name of test data in `path` directory.\n","* **ignore_columns (optional): ** Any columns in the CSV files that you may want to ignore for the purposes of training. These should be included here. \n","\n","Note that the train, validation and test CSVs must all share the same schema, i.e., they should have the same columns. Processing data involves several steps and can take several minutes to complete, especially if this is the first time you are running the `deepmatcher` package.\n","\n","NOTE: If you are running this in Colab, you may get a message saying 'Memory usage is close to the limit.' You can safely ignore it for now. We are working on reducing the memory footprint."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"WJ37wi1HC9EJ","colab":{"base_uri":"https://localhost:8080/","height":323},"executionInfo":{"status":"ok","timestamp":1599596979441,"user_tz":-120,"elapsed":432954,"user":{"displayName":"Zoé Goey","photoUrl":"","userId":"18241306402691044040"}},"outputId":"3d756959-d533-43e8-80c4-fab1738d7eee"},"source":["train, validation, test = dm.data.process(\n","    path='sample_data/itunes-amazon',\n","    train='train.csv',\n","    validation='validation.csv',\n","    test='test.csv')"],"execution_count":6,"outputs":[{"output_type":"stream","text":["\n","Reading and processing data from \"sample_data/itunes-amazon/train.csv\"\n","0% [############################# ] 100% | ETA: 00:00:00\n","Reading and processing data from \"sample_data/itunes-amazon/validation.csv\"\n","0% [############################# ] 100% | ETA: 00:00:00\n","Reading and processing data from \"sample_data/itunes-amazon/test.csv\"\n","0% [############################# ] 100% | ETA: 00:00:00INFO:deepmatcher.data.field:Downloading vectors from https://drive.google.com/uc?export=download&id=1Vih8gAmgBnuYDxfblbT94P6WjB7s1ZSh\n"],"name":"stderr"},{"output_type":"stream","text":["downloading from Google Drive; may take a few minutes\n"],"name":"stdout"},{"output_type":"stream","text":["wiki.en.bin: 8.49GB [03:02, 46.7MB/s]\n","INFO:deepmatcher.data.field:Extracting vectors into /root/.vector_cache\n","\n","Building vocabulary\n","0% [#] 100% | ETA: 00:00:00\n","Total time elapsed: 00:00:00\n","\n","Computing principal components\n","0% [#] 100% | ETA: 00:00:00\n","Total time elapsed: 00:00:00\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"4RCEIm8MQJO3"},"source":["#### Peeking at processed data\n","Let's take a look at how the processed data looks like. To do this, we get the raw `pandas` table corresponding to the processed training dataset object. "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"qmkzAzWOQJO3","colab":{},"executionInfo":{"status":"ok","timestamp":1599597483621,"user_tz":-120,"elapsed":554,"user":{"displayName":"Zoé Goey","photoUrl":"","userId":"18241306402691044040"}}},"source":["train_table = train.get_raw_table()\n","train_table.head()\n","train_table.index.name"],"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"hpo4JpshQJO6"},"source":["The processed attribute values have been tokenized and lowercased so they may not look exactly the same as the input training data. These modifications help the neural network generalize better, i.e., perform better on data not trained on. "]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"8mr3oVzuQJO6"},"source":["## Step 2. Define neural network model\n","\n","In this step you tell `deepmatcher` what kind of neural network you would like to use for entity matching. The easiest way to do this is to use one of the several kinds of neural network models that comes built-in with `deepmatcher`. To use a built-in network, construct a `dm.MatchingModel` as follows:\n","\n","`model = dm.MatchingModel(attr_summarizer='<TYPE>')`\n","\n","where `<TYPE>` is one of `sif`, `rnn`, `attention` or `hybrid`. If you are not familiar with what these mean, we strongly recommend taking a look at either **[slides from our talk on deepmatcher](http://bit.do/deepmatcher-talk)** for a high level overview, or **[our paper](http://pages.cs.wisc.edu/~anhai/papers1/deepmatcher-sigmod18.pdf)** for a more detailed explanation. Here we give briefly describe the intuition behind these four model types:\n","* **sif:** This model considers the **words** present in each attribute value pair to determine a match or non-match. It does not take word order into account.\n","* **rnn:** This model considers the **sequences of words** present in each attribute value pair to determine a match or non-match.\n","* **attention:** This model considers the **alignment of words** present in each attribute value pair to determine a match or non-match. It does not take word order into account.\n","* **hybrid:** This model considers the **alignment of sequences of words** present in each attribute value pair to determine a match or non-match. This is the default.\n","\n","`deepmatcher` is highly customizable and allows you to tune almost every aspect of the neural network model for your application scenario. **[This tutorial](https://nbviewer.jupyter.org/github/anhaidgroup/deepmatcher/blob/master/examples/matching_models.ipynb)** discusses the structure of `MatchingModel`s and how they can be customized.\n","\n","For this tutorial, let's create a `hybrid` model for entity matching:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"NwUE2jMXQJO7","colab":{},"executionInfo":{"status":"ok","timestamp":1599597518172,"user_tz":-120,"elapsed":502,"user":{"displayName":"Zoé Goey","photoUrl":"","userId":"18241306402691044040"}}},"source":["model = dm.MatchingModel(attr_summarizer='hybrid')"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"7iLAHpuVQJO9"},"source":["## Step 3. Train model\n","\n","Next, we train the defined neural network model using the processed training and validation data. To do so, we call the `run_train` method which takes the following basic parameters:\n","\n","* **train:** The processed training dataset object (of type `MatchingDataset`).\n","* **validation:** The processed validation dataset object (of type `MatchingDataset`).\n","* **epochs:** Number of times to go over the entire `train` data for training the model.\n","* **batch_size:** Number of labeled examples (tuple pairs) to use for each training step. This value may be increased if you have a lot of training data and would like to speed up training. The optimal value is dataset dependent.\n","* **best_save_path:** Path to save the best model.\n","* **pos_neg_ratio**: The ratio of the weight of positive examples (matches) to weight of negative examples (non-matches). This value should be increased if you have fewer matches than non-matches in your data. The optimal value is dataset dependent.\n","\n","Many other aspects of the training algorithm can be customized. For details on this, please refer the API documentation for **[run_train]()**"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"RIZclsK1QJO-","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1599597625013,"user_tz":-120,"elapsed":103904,"user":{"displayName":"Zoé Goey","photoUrl":"","userId":"18241306402691044040"}},"outputId":"ab07d044-af55-4b1b-ac70-706f33e4f878"},"source":["model.run_train(\n","    train,\n","    validation,\n","    epochs=10,\n","    batch_size=16,\n","    best_save_path='hybrid_model.pth',\n","    pos_neg_ratio=3)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["* Number of trainable parameters: 17757810\n","===>  TRAIN Epoch 1\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2352: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n","  warnings.warn(\"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n","0% [████] 100% | ETA: 00:00:00\n","Total time elapsed: 00:00:06\n"],"name":"stderr"},{"output_type":"stream","text":["Finished Epoch 1 || Run Time:    6.2 | Load Time:    1.2 || F1:  44.66 | Prec:  35.66 | Rec:  59.74 || Ex/s:  43.24\n","\n","===>  EVAL Epoch 1\n"],"name":"stdout"},{"output_type":"stream","text":["0% [█] 100% | ETA: 00:00:00\n","Total time elapsed: 00:00:00\n"],"name":"stderr"},{"output_type":"stream","text":["Finished Epoch 1 || Run Time:    0.9 | Load Time:    0.4 || F1:  60.32 | Prec:  48.72 | Rec:  79.17 || Ex/s:  82.65\n","\n","* Best F1: tensor(60.3175, device='cuda:0')\n","Saving best model...\n","Done.\n","---------------------\n","\n","===>  TRAIN Epoch 2\n"],"name":"stdout"},{"output_type":"stream","text":["0% [████] 100% | ETA: 00:00:00\n","Total time elapsed: 00:00:06\n"],"name":"stderr"},{"output_type":"stream","text":["Finished Epoch 2 || Run Time:    5.5 | Load Time:    1.1 || F1:  78.41 | Prec:  69.70 | Rec:  89.61 || Ex/s:  48.49\n","\n","===>  EVAL Epoch 2\n"],"name":"stdout"},{"output_type":"stream","text":["0% [█] 100% | ETA: 00:00:00\n","Total time elapsed: 00:00:00\n"],"name":"stderr"},{"output_type":"stream","text":["Finished Epoch 2 || Run Time:    0.9 | Load Time:    0.4 || F1:  70.00 | Prec:  58.33 | Rec:  87.50 || Ex/s:  85.14\n","\n","* Best F1: tensor(70., device='cuda:0')\n","Saving best model...\n","Done.\n","---------------------\n","\n","===>  TRAIN Epoch 3\n"],"name":"stdout"},{"output_type":"stream","text":["0% [████] 100% | ETA: 00:00:00\n","Total time elapsed: 00:00:06\n"],"name":"stderr"},{"output_type":"stream","text":["Finished Epoch 3 || Run Time:    5.9 | Load Time:    1.1 || F1:  91.46 | Prec:  86.21 | Rec:  97.40 || Ex/s:  45.89\n","\n","===>  EVAL Epoch 3\n"],"name":"stdout"},{"output_type":"stream","text":["0% [█] 100% | ETA: 00:00:00\n","Total time elapsed: 00:00:00\n"],"name":"stderr"},{"output_type":"stream","text":["Finished Epoch 3 || Run Time:    0.9 | Load Time:    0.4 || F1:  74.19 | Prec:  60.53 | Rec:  95.83 || Ex/s:  87.02\n","\n","* Best F1: tensor(74.1936, device='cuda:0')\n","Saving best model...\n","Done.\n","---------------------\n","\n","===>  TRAIN Epoch 4\n"],"name":"stdout"},{"output_type":"stream","text":["0% [████] 100% | ETA: 00:00:00\n","Total time elapsed: 00:00:06\n"],"name":"stderr"},{"output_type":"stream","text":["Finished Epoch 4 || Run Time:    5.4 | Load Time:    1.1 || F1:  96.20 | Prec:  93.83 | Rec:  98.70 || Ex/s:  49.36\n","\n","===>  EVAL Epoch 4\n"],"name":"stdout"},{"output_type":"stream","text":["0% [█] 100% | ETA: 00:00:00\n","Total time elapsed: 00:00:00\n"],"name":"stderr"},{"output_type":"stream","text":["Finished Epoch 4 || Run Time:    0.9 | Load Time:    0.4 || F1:  83.64 | Prec:  74.19 | Rec:  95.83 || Ex/s:  87.00\n","\n","* Best F1: tensor(83.6364, device='cuda:0')\n","Saving best model...\n","Done.\n","---------------------\n","\n","===>  TRAIN Epoch 5\n"],"name":"stdout"},{"output_type":"stream","text":["0% [████] 100% | ETA: 00:00:00\n","Total time elapsed: 00:00:06\n"],"name":"stderr"},{"output_type":"stream","text":["Finished Epoch 5 || Run Time:    5.5 | Load Time:    1.1 || F1:  97.40 | Prec:  97.40 | Rec:  97.40 || Ex/s:  48.80\n","\n","===>  EVAL Epoch 5\n"],"name":"stdout"},{"output_type":"stream","text":["0% [█] 100% | ETA: 00:00:00\n","Total time elapsed: 00:00:00\n"],"name":"stderr"},{"output_type":"stream","text":["Finished Epoch 5 || Run Time:    0.9 | Load Time:    0.4 || F1:  92.00 | Prec:  88.46 | Rec:  95.83 || Ex/s:  85.63\n","\n","* Best F1: tensor(92., device='cuda:0')\n","Saving best model...\n","Done.\n","---------------------\n","\n","===>  TRAIN Epoch 6\n"],"name":"stdout"},{"output_type":"stream","text":["0% [████] 100% | ETA: 00:00:00\n","Total time elapsed: 00:00:06\n"],"name":"stderr"},{"output_type":"stream","text":["Finished Epoch 6 || Run Time:    5.5 | Load Time:    1.1 || F1:  98.70 | Prec:  98.70 | Rec:  98.70 || Ex/s:  48.51\n","\n","===>  EVAL Epoch 6\n"],"name":"stdout"},{"output_type":"stream","text":["0% [█] 100% | ETA: 00:00:00\n","Total time elapsed: 00:00:00\n"],"name":"stderr"},{"output_type":"stream","text":["Finished Epoch 6 || Run Time:    0.9 | Load Time:    0.4 || F1:  91.67 | Prec:  91.67 | Rec:  91.67 || Ex/s:  85.83\n","\n","---------------------\n","\n","===>  TRAIN Epoch 7\n"],"name":"stdout"},{"output_type":"stream","text":["0% [████] 100% | ETA: 00:00:00\n","Total time elapsed: 00:00:06\n"],"name":"stderr"},{"output_type":"stream","text":["Finished Epoch 7 || Run Time:    5.6 | Load Time:    1.1 || F1: 100.00 | Prec: 100.00 | Rec: 100.00 || Ex/s:  47.58\n","\n","===>  EVAL Epoch 7\n"],"name":"stdout"},{"output_type":"stream","text":["0% [█] 100% | ETA: 00:00:00\n","Total time elapsed: 00:00:00\n"],"name":"stderr"},{"output_type":"stream","text":["Finished Epoch 7 || Run Time:    0.9 | Load Time:    0.4 || F1:  88.00 | Prec:  84.62 | Rec:  91.67 || Ex/s:  83.81\n","\n","---------------------\n","\n","===>  TRAIN Epoch 8\n"],"name":"stdout"},{"output_type":"stream","text":["0% [████] 100% | ETA: 00:00:00\n","Total time elapsed: 00:00:06\n"],"name":"stderr"},{"output_type":"stream","text":["Finished Epoch 8 || Run Time:    5.6 | Load Time:    1.1 || F1: 100.00 | Prec: 100.00 | Rec: 100.00 || Ex/s:  47.68\n","\n","===>  EVAL Epoch 8\n"],"name":"stdout"},{"output_type":"stream","text":["0% [█] 100% | ETA: 00:00:00\n","Total time elapsed: 00:00:00\n"],"name":"stderr"},{"output_type":"stream","text":["Finished Epoch 8 || Run Time:    0.9 | Load Time:    0.4 || F1:  90.20 | Prec:  85.19 | Rec:  95.83 || Ex/s:  85.28\n","\n","---------------------\n","\n","===>  TRAIN Epoch 9\n"],"name":"stdout"},{"output_type":"stream","text":["0% [████] 100% | ETA: 00:00:00\n","Total time elapsed: 00:00:06\n"],"name":"stderr"},{"output_type":"stream","text":["Finished Epoch 9 || Run Time:    5.5 | Load Time:    1.1 || F1: 100.00 | Prec: 100.00 | Rec: 100.00 || Ex/s:  48.61\n","\n","===>  EVAL Epoch 9\n"],"name":"stdout"},{"output_type":"stream","text":["0% [█] 100% | ETA: 00:00:00\n","Total time elapsed: 00:00:00\n"],"name":"stderr"},{"output_type":"stream","text":["Finished Epoch 9 || Run Time:    0.9 | Load Time:    0.4 || F1:  90.20 | Prec:  85.19 | Rec:  95.83 || Ex/s:  87.47\n","\n","---------------------\n","\n","===>  TRAIN Epoch 10\n"],"name":"stdout"},{"output_type":"stream","text":["0% [████] 100% | ETA: 00:00:00\n","Total time elapsed: 00:00:06\n"],"name":"stderr"},{"output_type":"stream","text":["Finished Epoch 10 || Run Time:    5.4 | Load Time:    1.1 || F1: 100.00 | Prec: 100.00 | Rec: 100.00 || Ex/s:  49.24\n","\n","===>  EVAL Epoch 10\n"],"name":"stdout"},{"output_type":"stream","text":["0% [█] 100% | ETA: 00:00:00\n","Total time elapsed: 00:00:00\n"],"name":"stderr"},{"output_type":"stream","text":["Finished Epoch 10 || Run Time:    0.9 | Load Time:    0.4 || F1:  90.20 | Prec:  85.19 | Rec:  95.83 || Ex/s:  86.77\n","\n","---------------------\n","\n","Loading best model...\n","Training done.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["tensor(92., device='cuda:0')"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"lejVqpjAQJPD"},"source":["## Step 4. Apply model to new data\n","\n","### Evaluating on test data\n","Now that we have a trained model for entity matching, we can now evaluate its accuracy on test data, to estimate the performance of the model on unlabeled data."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"jLoneAI_QJPD","colab":{"base_uri":"https://localhost:8080/","height":85},"executionInfo":{"status":"ok","timestamp":1599598867340,"user_tz":-120,"elapsed":1589,"user":{"displayName":"Zoé Goey","photoUrl":"","userId":"18241306402691044040"}},"outputId":"d9700965-03dc-438c-fc7f-ccb7bd9083a3"},"source":["# Compute F1 on test set\n","model.run_eval(test)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["===>  EVAL Epoch 5\n","Finished Epoch 5 || Run Time:    0.6 | Load Time:    0.4 || F1:  85.25 | Prec:  86.67 | Rec:  83.87 || Ex/s: 112.56\n","\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["tensor(85.2459, device='cuda:0')"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"9SsDO9uXYD89","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599598902198,"user_tz":-120,"elapsed":704,"user":{"displayName":"Zoé Goey","photoUrl":"","userId":"18241306402691044040"}}},"source":["try:\n","    import recordlinkage\n","except:\n","    !pip install -qqq recordlinkage"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"42xDP-GUYD9B","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1599598907592,"user_tz":-120,"elapsed":610,"user":{"displayName":"Zoé Goey","photoUrl":"","userId":"18241306402691044040"}},"outputId":"8dc47cf4-3142-44ca-fc45-68bbbd72b07c"},"source":["# Comparison step\n","compare_cl = recordlinkage.Compare()\n","compare_cl.string('Song_Name', 'Song_Name', method='jarowinkler', threshold=0.9,label = 'Song_Name')\n","compare_cl.string('Artist_Name', 'Artist_Name', method='jarowinkler', threshold=0.9,label = 'Artist_Name')\n","compare_cl.exact('Album_Name', 'Album_Name', label = 'Album_Name')\n","compare_cl.exact('Genre', 'Genre',  label = 'Genre')"],"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<Compare>"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"rjKDqopqYD9D","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599599445772,"user_tz":-120,"elapsed":543,"user":{"displayName":"Zoé Goey","photoUrl":"","userId":"18241306402691044040"}}},"source":["# Load data\n","true_links = {}\n","features = {}\n","validation = {}\n","datasets= {'train':r'sample_data/itunes-amazon/train.csv', \n","'test':r'sample_data/itunes-amazon/test.csv',\n","'validation':r'sample_data/itunes-amazon/validation.csv'}"],"execution_count":34,"outputs":[]},{"cell_type":"code","metadata":{"id":"f0ej2gBJYD9G","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599599447606,"user_tz":-120,"elapsed":656,"user":{"displayName":"Zoé Goey","photoUrl":"","userId":"18241306402691044040"}}},"source":["# Some helper functions\n","def print_results(name, table):\n","    print(\"\".join(['*' for x in range(len(name) + 1)]))\n","    print('{}'.format(name))\n","    print(\"\".join(['*' for x in range(len(name) + 1)]))\n","    print(\"Confusion matrix:\")\n","    print(table['confusion_matrix'])\n","    print(\"Accuracy: {}\".format(table['accuracy']))\n","    print(\"Recall: {}\".format(table['recall']))\n","    print(\"F-score: {}\".format(table['f-score']))\n","    print('\\n')\n","    \n","def performance_metrics(true_links, result, set_size):\n","    validation = {}\n","    validation['confusion_matrix'] = recordlinkage.confusion_matrix(true_links, result, set_size)\n","    validation['accuracy'] = recordlinkage.accuracy(true_links, result, len(features['validation']))\n","    validation['recall'] = recordlinkage.recall(true_links, result)\n","    validation['f-score'] = recordlinkage.fscore(true_links, result)\n","    return validation"],"execution_count":35,"outputs":[]},{"cell_type":"code","metadata":{"id":"oQ9HNmU0YD9I","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599599449652,"user_tz":-120,"elapsed":566,"user":{"displayName":"Zoé Goey","photoUrl":"","userId":"18241306402691044040"}}},"source":["# Train and validate various classifiers\n","classifiers= {\n","'Hand-tuned':None,\n","'Logistic regression':recordlinkage.LogisticRegressionClassifier(),\n","'Naive Bayes': recordlinkage.NaiveBayesClassifier(),\n","'Support vector machine': recordlinkage.SVMClassifier(),\n","'K-means': recordlinkage.KMeansClassifier(),\n","'ECM': recordlinkage.ECMClassifier()}\n","for key in datasets:\n","    df = pd.read_csv(datasets[key])\n","    nof_cols = int((df.shape[1] - 2)/2)\n","    dfA = df.iloc[:,2:nof_cols + 2]\n","    dfB = df.iloc[:,nof_cols + 2:df.shape[1]]\n","    dfA.rename(columns={c:c[5:] for c in dfA.columns },inplace=True)\n","    dfB.rename(columns={c:c[6:] for c in dfB.columns },inplace=True)\n","\n","    tuples = [(i,i) for i in range(len(df)) if df.iloc[i]['label'] == 1]\n","    true_links[key] = pd.MultiIndex.from_tuples(tuples)\n","\n","    tuples_full = [(i,i) for i in range(len(df))]\n","    candidate_links = pd.MultiIndex.from_tuples(tuples_full)\n","    # Final features (used in other methods as well)\n","    features[key] = compare_cl.compute(candidate_links, dfA, dfB)"],"execution_count":36,"outputs":[]},{"cell_type":"code","metadata":{"id":"qPKWiwXwYD9L","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1599599452122,"user_tz":-120,"elapsed":748,"user":{"displayName":"Zoé Goey","photoUrl":"","userId":"18241306402691044040"}},"outputId":"69e4cc03-56d1-4ae0-d131-c99542886a38"},"source":["for key in classifiers:\n","    validation[key] = {}\n","    if key == 'Hand-tuned':\n","        # Immediate prediction\n","        result = features['validation'][features['validation'].sum(axis=1) > 2].index\n","    else:\n","        # Training \n","        if key == 'ECM':\n","            classifiers[key].fit(features['train']) # somehow ECM cannot ignore redundant argument, opposed to K-Means\n","        else:\n","            classifiers[key].fit(features['train'], true_links['train'])\n","        # Predict the match status for all test record pairs\n","        result =  classifiers[key].predict(features['validation'])\n","        \n","    # Validate\n","    validation[key] = performance_metrics(true_links['validation'], result, len(features['validation']))\n","    \n","    #Print results\n","    print_results(key, validation[key])\n"],"execution_count":37,"outputs":[{"output_type":"stream","text":["***********\n","Hand-tuned\n","***********\n","Confusion matrix:\n","[[ 7 17]\n"," [ 0 84]]\n","Accuracy: 0.8425925925925926\n","Recall: 0.2916666666666667\n","F-score: 0.45161290322580644\n","\n","\n","********************\n","Logistic regression\n","********************\n","Confusion matrix:\n","[[18  6]\n"," [ 1 83]]\n","Accuracy: 0.9351851851851852\n","Recall: 0.75\n","F-score: 0.8372093023255814\n","\n","\n","************\n","Naive Bayes\n","************\n","Confusion matrix:\n","[[18  6]\n"," [ 1 83]]\n","Accuracy: 0.9351851851851852\n","Recall: 0.75\n","F-score: 0.8372093023255814\n","\n","\n","***********************\n","Support vector machine\n","***********************\n","Confusion matrix:\n","[[18  6]\n"," [ 1 83]]\n","Accuracy: 0.9351851851851852\n","Recall: 0.75\n","F-score: 0.8372093023255814\n","\n","\n","********\n","K-means\n","********\n","Confusion matrix:\n","[[ 7 17]\n"," [ 0 84]]\n","Accuracy: 0.8425925925925926\n","Recall: 0.2916666666666667\n","F-score: 0.45161290322580644\n","\n","\n","****\n","ECM\n","****\n","Confusion matrix:\n","[[ 9 15]\n"," [ 6 78]]\n","Accuracy: 0.8055555555555556\n","Recall: 0.375\n","F-score: 0.4615384615384615\n","\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xC2Z4DahYD9P","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1599599467005,"user_tz":-120,"elapsed":550,"user":{"displayName":"Zoé Goey","photoUrl":"","userId":"18241306402691044040"}},"outputId":"698dd539-4a93-40cb-9280-ca32b315a8db"},"source":["# Test results for best method\n","f_scores = {key:validation[key]['f-score'] for key in validation}\n","best_model = max(f_scores, key = f_scores.get) \n","if best_model == 'Hand-tuned':\n","    result = features['test'][features['test'].sum(axis=1) > 2].index\n","else:\n","    result = classifiers[best_model].predict(features['test'])\n","test =  performance_metrics(true_links['test'], result, len(features['test']))\n","print_results(\"Selected model ({}) on test set\".format(best_model), test)\n"],"execution_count":38,"outputs":[{"output_type":"stream","text":["*************************************************\n","Selected model (Logistic regression) on test set\n","*************************************************\n","Confusion matrix:\n","[[25  6]\n"," [ 1 76]]\n","Accuracy: 0.9351851851851852\n","Recall: 0.8064516129032258\n","F-score: 0.8771929824561403\n","\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"08o48bZOYD9R","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dM3u-t24YD9T","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}