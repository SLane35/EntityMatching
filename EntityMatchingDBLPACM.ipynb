{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aXpIRSAQ-cw1"
   },
   "source": [
    "# Entity Matching\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sBtZVvrSQJOf"
   },
   "source": [
    "## Setup Python environment\n",
    "\n",
    "If you are running this notebook inside Colab, you will first need to install necessary packages by running the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 31550,
     "status": "ok",
     "timestamp": 1599596461976,
     "user": {
      "displayName": "Zoé Goey",
      "photoUrl": "",
      "userId": "18241306402691044040"
     },
     "user_tz": -120
    },
    "id": "LEiDiDNz-PEG",
    "outputId": "4f3ccd0c-8b69-4eb8-bd58-a0b92acc5392"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import deepmatcher as dm\n",
    "except:\n",
    "    !pip install git+https://github.com/anhaidgroup/deepmatcher.git\n",
    "    import deepmatcher as dm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g6inOGkQQJOn"
   },
   "source": [
    "We recommend having a GPU available for the DeepMatcher training. In case a GPU is not available, we will use all available CPU cores. You can run the following command to determine if a GPU is available and will be used for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 599,
     "status": "ok",
     "timestamp": 1599596479885,
     "user": {
      "displayName": "Zoé Goey",
      "photoUrl": "",
      "userId": "18241306402691044040"
     },
     "user_tz": -120
    },
    "id": "GYb5r0etQJOo",
    "outputId": "5de9d935-164b-4415-b2a1-8d4b3f97af03"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import recordlinkage\n",
    "except:\n",
    "    !pip install -qqq recordlinkage\n",
    "    import recordlinkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dv_sFh1_QJOs"
   },
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lu6QgmbDQJOv"
   },
   "source": [
    "Read the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 479
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 626,
     "status": "ok",
     "timestamp": 1599596540258,
     "user": {
      "displayName": "Zoé Goey",
      "photoUrl": "",
      "userId": "18241306402691044040"
     },
     "user_tz": -120
    },
    "id": "lpsH6NEZQJOw",
    "outputId": "59e046fd-9a5e-45ed-f8b2-cf1e952f1a32"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>venue</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>journals/sigmod/Mackay99</td>\n",
       "      <td>Semantic Integration of Environmental Models f...</td>\n",
       "      <td>D. Scott Mackay</td>\n",
       "      <td>SIGMOD Record</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>conf/vldb/PoosalaI96</td>\n",
       "      <td>Estimation of Query-Result Distribution and it...</td>\n",
       "      <td>Viswanath Poosala, Yannis E. Ioannidis</td>\n",
       "      <td>VLDB</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>conf/vldb/PalpanasSCP02</td>\n",
       "      <td>Incremental Maintenance for Non-Distributive A...</td>\n",
       "      <td>Themistoklis Palpanas, Richard Sidle, Hamid Pi...</td>\n",
       "      <td>VLDB</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>conf/vldb/GardarinGT96</td>\n",
       "      <td>Cost-based Selection of Path Expression Proces...</td>\n",
       "      <td>Zhao-Hui Tang, Georges Gardarin, Jean-Robert G...</td>\n",
       "      <td>VLDB</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>conf/vldb/HoelS95</td>\n",
       "      <td>Benchmarking Spatial Join Operations with Spat...</td>\n",
       "      <td>Erik G. Hoel, Hanan Samet</td>\n",
       "      <td>VLDB</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id  \\\n",
       "0  journals/sigmod/Mackay99   \n",
       "1      conf/vldb/PoosalaI96   \n",
       "2   conf/vldb/PalpanasSCP02   \n",
       "3    conf/vldb/GardarinGT96   \n",
       "4         conf/vldb/HoelS95   \n",
       "\n",
       "                                               title  \\\n",
       "0  Semantic Integration of Environmental Models f...   \n",
       "1  Estimation of Query-Result Distribution and it...   \n",
       "2  Incremental Maintenance for Non-Distributive A...   \n",
       "3  Cost-based Selection of Path Expression Proces...   \n",
       "4  Benchmarking Spatial Join Operations with Spat...   \n",
       "\n",
       "                                             authors          venue  year  \n",
       "0                                    D. Scott Mackay  SIGMOD Record  1999  \n",
       "1             Viswanath Poosala, Yannis E. Ioannidis           VLDB  1996  \n",
       "2  Themistoklis Palpanas, Richard Sidle, Hamid Pi...           VLDB  2002  \n",
       "3  Zhao-Hui Tang, Georges Gardarin, Jean-Robert G...           VLDB  1996  \n",
       "4                          Erik G. Hoel, Hanan Samet           VLDB  1995  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>venue</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>304586</td>\n",
       "      <td>The WASA2 object-oriented workflow management ...</td>\n",
       "      <td>Gottfried Vossen, Mathias Weske</td>\n",
       "      <td>International Conference on Management of Data</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>304587</td>\n",
       "      <td>A user-centered interface for querying distrib...</td>\n",
       "      <td>Isabel F. Cruz, Kimberly M. James</td>\n",
       "      <td>International Conference on Management of Data</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>304589</td>\n",
       "      <td>World Wide Database-integrating the Web, CORBA...</td>\n",
       "      <td>Athman Bouguettaya, Boualem Benatallah, Lily H...</td>\n",
       "      <td>International Conference on Management of Data</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>304590</td>\n",
       "      <td>XML-based information mediation with MIX</td>\n",
       "      <td>Chaitan Baru, Amarnath Gupta, Bertram Lud&amp;#228...</td>\n",
       "      <td>International Conference on Management of Data</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>304582</td>\n",
       "      <td>The CCUBE constraint object-oriented database ...</td>\n",
       "      <td>Alexander Brodsky, Victor E. Segal, Jia Chen, ...</td>\n",
       "      <td>International Conference on Management of Data</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                              title  \\\n",
       "0  304586  The WASA2 object-oriented workflow management ...   \n",
       "1  304587  A user-centered interface for querying distrib...   \n",
       "2  304589  World Wide Database-integrating the Web, CORBA...   \n",
       "3  304590           XML-based information mediation with MIX   \n",
       "4  304582  The CCUBE constraint object-oriented database ...   \n",
       "\n",
       "                                             authors  \\\n",
       "0                    Gottfried Vossen, Mathias Weske   \n",
       "1                  Isabel F. Cruz, Kimberly M. James   \n",
       "2  Athman Bouguettaya, Boualem Benatallah, Lily H...   \n",
       "3  Chaitan Baru, Amarnath Gupta, Bertram Lud&#228...   \n",
       "4  Alexander Brodsky, Victor E. Segal, Jia Chen, ...   \n",
       "\n",
       "                                            venue  year  \n",
       "0  International Conference on Management of Data  1999  \n",
       "1  International Conference on Management of Data  1999  \n",
       "2  International Conference on Management of Data  1999  \n",
       "3  International Conference on Management of Data  1999  \n",
       "4  International Conference on Management of Data  1999  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "left_df = pd.read_csv('Data/DBLP2.csv', encoding='cp1252')\n",
    "right_df = pd.read_csv('Data/ACM.csv', encoding='cp1252')\n",
    "display(left_df.head())\n",
    "display(right_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label columns as left/right and then form Cartesian product:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left_id</th>\n",
       "      <th>left_title</th>\n",
       "      <th>left_authors</th>\n",
       "      <th>left_venue</th>\n",
       "      <th>left_year</th>\n",
       "      <th>right_id</th>\n",
       "      <th>right_title</th>\n",
       "      <th>right_authors</th>\n",
       "      <th>right_venue</th>\n",
       "      <th>right_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>journals/sigmod/Mackay99</td>\n",
       "      <td>Semantic Integration of Environmental Models f...</td>\n",
       "      <td>D. Scott Mackay</td>\n",
       "      <td>SIGMOD Record</td>\n",
       "      <td>1999</td>\n",
       "      <td>304586</td>\n",
       "      <td>The WASA2 object-oriented workflow management ...</td>\n",
       "      <td>Gottfried Vossen, Mathias Weske</td>\n",
       "      <td>International Conference on Management of Data</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>journals/sigmod/Mackay99</td>\n",
       "      <td>Semantic Integration of Environmental Models f...</td>\n",
       "      <td>D. Scott Mackay</td>\n",
       "      <td>SIGMOD Record</td>\n",
       "      <td>1999</td>\n",
       "      <td>304587</td>\n",
       "      <td>A user-centered interface for querying distrib...</td>\n",
       "      <td>Isabel F. Cruz, Kimberly M. James</td>\n",
       "      <td>International Conference on Management of Data</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>journals/sigmod/Mackay99</td>\n",
       "      <td>Semantic Integration of Environmental Models f...</td>\n",
       "      <td>D. Scott Mackay</td>\n",
       "      <td>SIGMOD Record</td>\n",
       "      <td>1999</td>\n",
       "      <td>304589</td>\n",
       "      <td>World Wide Database-integrating the Web, CORBA...</td>\n",
       "      <td>Athman Bouguettaya, Boualem Benatallah, Lily H...</td>\n",
       "      <td>International Conference on Management of Data</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>journals/sigmod/Mackay99</td>\n",
       "      <td>Semantic Integration of Environmental Models f...</td>\n",
       "      <td>D. Scott Mackay</td>\n",
       "      <td>SIGMOD Record</td>\n",
       "      <td>1999</td>\n",
       "      <td>304590</td>\n",
       "      <td>XML-based information mediation with MIX</td>\n",
       "      <td>Chaitan Baru, Amarnath Gupta, Bertram Lud&amp;#228...</td>\n",
       "      <td>International Conference on Management of Data</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>journals/sigmod/Mackay99</td>\n",
       "      <td>Semantic Integration of Environmental Models f...</td>\n",
       "      <td>D. Scott Mackay</td>\n",
       "      <td>SIGMOD Record</td>\n",
       "      <td>1999</td>\n",
       "      <td>304582</td>\n",
       "      <td>The CCUBE constraint object-oriented database ...</td>\n",
       "      <td>Alexander Brodsky, Victor E. Segal, Jia Chen, ...</td>\n",
       "      <td>International Conference on Management of Data</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    left_id  \\\n",
       "0  journals/sigmod/Mackay99   \n",
       "1  journals/sigmod/Mackay99   \n",
       "2  journals/sigmod/Mackay99   \n",
       "3  journals/sigmod/Mackay99   \n",
       "4  journals/sigmod/Mackay99   \n",
       "\n",
       "                                          left_title     left_authors  \\\n",
       "0  Semantic Integration of Environmental Models f...  D. Scott Mackay   \n",
       "1  Semantic Integration of Environmental Models f...  D. Scott Mackay   \n",
       "2  Semantic Integration of Environmental Models f...  D. Scott Mackay   \n",
       "3  Semantic Integration of Environmental Models f...  D. Scott Mackay   \n",
       "4  Semantic Integration of Environmental Models f...  D. Scott Mackay   \n",
       "\n",
       "      left_venue  left_year  right_id  \\\n",
       "0  SIGMOD Record       1999    304586   \n",
       "1  SIGMOD Record       1999    304587   \n",
       "2  SIGMOD Record       1999    304589   \n",
       "3  SIGMOD Record       1999    304590   \n",
       "4  SIGMOD Record       1999    304582   \n",
       "\n",
       "                                         right_title  \\\n",
       "0  The WASA2 object-oriented workflow management ...   \n",
       "1  A user-centered interface for querying distrib...   \n",
       "2  World Wide Database-integrating the Web, CORBA...   \n",
       "3           XML-based information mediation with MIX   \n",
       "4  The CCUBE constraint object-oriented database ...   \n",
       "\n",
       "                                       right_authors  \\\n",
       "0                    Gottfried Vossen, Mathias Weske   \n",
       "1                  Isabel F. Cruz, Kimberly M. James   \n",
       "2  Athman Bouguettaya, Boualem Benatallah, Lily H...   \n",
       "3  Chaitan Baru, Amarnath Gupta, Bertram Lud&#228...   \n",
       "4  Alexander Brodsky, Victor E. Segal, Jia Chen, ...   \n",
       "\n",
       "                                      right_venue  right_year  \n",
       "0  International Conference on Management of Data        1999  \n",
       "1  International Conference on Management of Data        1999  \n",
       "2  International Conference on Management of Data        1999  \n",
       "3  International Conference on Management of Data        1999  \n",
       "4  International Conference on Management of Data        1999  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "left_df_renamed =left_df.add_prefix('left_')\n",
    "left_df_renamed['join'] = 1\n",
    "right_df_renamed =right_df.add_prefix('right_')\n",
    "right_df_renamed['join'] = 1\n",
    "prod_df = pd.merge(left_df_renamed, right_df_renamed, on=\"join\")\n",
    "prod_df = prod_df.drop(columns=['join'])\n",
    "display(prod_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read true links and write them to product table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>left_title</th>\n",
       "      <th>left_authors</th>\n",
       "      <th>left_venue</th>\n",
       "      <th>left_year</th>\n",
       "      <th>right_title</th>\n",
       "      <th>right_authors</th>\n",
       "      <th>right_venue</th>\n",
       "      <th>right_year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1046262</th>\n",
       "      <td>0</td>\n",
       "      <td>Spatial Joins Using R-trees: Breadth-First Tra...</td>\n",
       "      <td>Ning Jing, Yun-Wu Huang, Elke A. Rundensteiner</td>\n",
       "      <td>VLDB</td>\n",
       "      <td>1997</td>\n",
       "      <td>Mind your vocabulary: query mapping across het...</td>\n",
       "      <td>Chen-Chuan K. Chang, H&amp;#233;ctor Garc&amp;#237;a-M...</td>\n",
       "      <td>International Conference on Management of Data</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723207</th>\n",
       "      <td>0</td>\n",
       "      <td>Declarative Data Cleaning: Language, Model, an...</td>\n",
       "      <td>Daniela Florescu, Cristian-Augustin Saita, Eri...</td>\n",
       "      <td>VLDB</td>\n",
       "      <td>2001</td>\n",
       "      <td>Transactional information systems: theory, alg...</td>\n",
       "      <td>Marc H. Scholl</td>\n",
       "      <td>ACM SIGMOD Record</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2621978</th>\n",
       "      <td>0</td>\n",
       "      <td>On-Line Warehouse View Maintenance</td>\n",
       "      <td>Jennifer Widom, Dallan Quass</td>\n",
       "      <td>SIGMOD Conference</td>\n",
       "      <td>1997</td>\n",
       "      <td>P-Grid: a self-organizing structured P2P system</td>\n",
       "      <td>Karl Aberer, Philippe Cudr&amp;#233;-Mauroux, Anwi...</td>\n",
       "      <td>ACM SIGMOD Record</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3330295</th>\n",
       "      <td>0</td>\n",
       "      <td>Querying and mining data streams: you only get...</td>\n",
       "      <td>Minos N. Garofalakis, Rajeev Rastogi, Johannes...</td>\n",
       "      <td>SIGMOD Conference</td>\n",
       "      <td>2002</td>\n",
       "      <td>Comprehension syntax</td>\n",
       "      <td>Peter Buneman, Leonid Libkin, Dan Suciu, Val T...</td>\n",
       "      <td>ACM SIGMOD Record</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3254369</th>\n",
       "      <td>0</td>\n",
       "      <td>On Parallel Execution of Multiple Pipelined Ha...</td>\n",
       "      <td>Philip S. Yu, Hui-I Hsiao, Ming-Syan Chen</td>\n",
       "      <td>SIGMOD Conference</td>\n",
       "      <td>1994</td>\n",
       "      <td>Bypassing Joins in Disjunctive Queries</td>\n",
       "      <td>Michael Steinbrunn, Klaus Peithner, Guido Moer...</td>\n",
       "      <td>Very Large Data Bases</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         label                                         left_title  \\\n",
       "id                                                                  \n",
       "1046262      0  Spatial Joins Using R-trees: Breadth-First Tra...   \n",
       "723207       0  Declarative Data Cleaning: Language, Model, an...   \n",
       "2621978      0                 On-Line Warehouse View Maintenance   \n",
       "3330295      0  Querying and mining data streams: you only get...   \n",
       "3254369      0  On Parallel Execution of Multiple Pipelined Ha...   \n",
       "\n",
       "                                              left_authors         left_venue  \\\n",
       "id                                                                              \n",
       "1046262     Ning Jing, Yun-Wu Huang, Elke A. Rundensteiner               VLDB   \n",
       "723207   Daniela Florescu, Cristian-Augustin Saita, Eri...               VLDB   \n",
       "2621978                       Jennifer Widom, Dallan Quass  SIGMOD Conference   \n",
       "3330295  Minos N. Garofalakis, Rajeev Rastogi, Johannes...  SIGMOD Conference   \n",
       "3254369          Philip S. Yu, Hui-I Hsiao, Ming-Syan Chen  SIGMOD Conference   \n",
       "\n",
       "         left_year                                        right_title  \\\n",
       "id                                                                      \n",
       "1046262       1997  Mind your vocabulary: query mapping across het...   \n",
       "723207        2001  Transactional information systems: theory, alg...   \n",
       "2621978       1997    P-Grid: a self-organizing structured P2P system   \n",
       "3330295       2002                               Comprehension syntax   \n",
       "3254369       1994             Bypassing Joins in Disjunctive Queries   \n",
       "\n",
       "                                             right_authors  \\\n",
       "id                                                           \n",
       "1046262  Chen-Chuan K. Chang, H&#233;ctor Garc&#237;a-M...   \n",
       "723207                                      Marc H. Scholl   \n",
       "2621978  Karl Aberer, Philippe Cudr&#233;-Mauroux, Anwi...   \n",
       "3330295  Peter Buneman, Leonid Libkin, Dan Suciu, Val T...   \n",
       "3254369  Michael Steinbrunn, Klaus Peithner, Guido Moer...   \n",
       "\n",
       "                                            right_venue  right_year  \n",
       "id                                                                   \n",
       "1046262  International Conference on Management of Data        1999  \n",
       "723207                               ACM SIGMOD Record         2001  \n",
       "2621978                              ACM SIGMOD Record         2003  \n",
       "3330295                              ACM SIGMOD Record         1994  \n",
       "3254369                           Very Large Data Bases        1995  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>left_title</th>\n",
       "      <th>left_authors</th>\n",
       "      <th>left_venue</th>\n",
       "      <th>left_year</th>\n",
       "      <th>right_title</th>\n",
       "      <th>right_authors</th>\n",
       "      <th>right_venue</th>\n",
       "      <th>right_year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5396296</th>\n",
       "      <td>1</td>\n",
       "      <td>Industrial Panel on Data Warehousing Technolog...</td>\n",
       "      <td>Umeshwar Dayal</td>\n",
       "      <td>VLDB</td>\n",
       "      <td>1999</td>\n",
       "      <td>Industrial Panel on Data Warehousing Technolog...</td>\n",
       "      <td>Umeshwar Dayal</td>\n",
       "      <td>Very Large Data Bases</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37056</th>\n",
       "      <td>1</td>\n",
       "      <td>Snowball: A Prototype System for Extracting Re...</td>\n",
       "      <td>Jeff Pavel, Luis Gravano, Aleksandr Voskoboyni...</td>\n",
       "      <td>SIGMOD Conference</td>\n",
       "      <td>2001</td>\n",
       "      <td>Snowball: a prototype system for extracting re...</td>\n",
       "      <td>Eugene Agichtein, Luis Gravano, Jeff Pavel, Vi...</td>\n",
       "      <td>International Conference on Management of Data</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4635259</th>\n",
       "      <td>1</td>\n",
       "      <td>Set Containment Joins: The Good, The Bad and T...</td>\n",
       "      <td>Karthikeyan Ramasamy, Jeffrey F. Naughton, Jig...</td>\n",
       "      <td>VLDB</td>\n",
       "      <td>2000</td>\n",
       "      <td>Set Containment Joins: The Good, The Bad and T...</td>\n",
       "      <td>Karthikeyan Ramasamy, Jignesh M. Patel, Jeffre...</td>\n",
       "      <td>Very Large Data Bases</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4299157</th>\n",
       "      <td>1</td>\n",
       "      <td>Optimization of Constrained Frequent Set Queri...</td>\n",
       "      <td>Laks V. S. Lakshmanan, Alex Pang, Raymond T. N...</td>\n",
       "      <td>SIGMOD Conference</td>\n",
       "      <td>1999</td>\n",
       "      <td>Optimization of constrained frequent set queri...</td>\n",
       "      <td>Laks V. S. Lakshmanan, Raymond Ng, Jiawei Han,...</td>\n",
       "      <td>International Conference on Management of Data</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373228</th>\n",
       "      <td>1</td>\n",
       "      <td>Temporal Database System Implementations</td>\n",
       "      <td>Michael H. Böhlen</td>\n",
       "      <td>SIGMOD Record</td>\n",
       "      <td>1995</td>\n",
       "      <td>Temporal database system implementations</td>\n",
       "      <td>Michael H. B&amp;#246;hlen</td>\n",
       "      <td>ACM SIGMOD Record</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         label                                         left_title  \\\n",
       "id                                                                  \n",
       "5396296      1  Industrial Panel on Data Warehousing Technolog...   \n",
       "37056        1  Snowball: A Prototype System for Extracting Re...   \n",
       "4635259      1  Set Containment Joins: The Good, The Bad and T...   \n",
       "4299157      1  Optimization of Constrained Frequent Set Queri...   \n",
       "373228       1           Temporal Database System Implementations   \n",
       "\n",
       "                                              left_authors         left_venue  \\\n",
       "id                                                                              \n",
       "5396296                                     Umeshwar Dayal               VLDB   \n",
       "37056    Jeff Pavel, Luis Gravano, Aleksandr Voskoboyni...  SIGMOD Conference   \n",
       "4635259  Karthikeyan Ramasamy, Jeffrey F. Naughton, Jig...               VLDB   \n",
       "4299157  Laks V. S. Lakshmanan, Alex Pang, Raymond T. N...  SIGMOD Conference   \n",
       "373228                                   Michael H. Böhlen      SIGMOD Record   \n",
       "\n",
       "         left_year                                        right_title  \\\n",
       "id                                                                      \n",
       "5396296       1999  Industrial Panel on Data Warehousing Technolog...   \n",
       "37056         2001  Snowball: a prototype system for extracting re...   \n",
       "4635259       2000  Set Containment Joins: The Good, The Bad and T...   \n",
       "4299157       1999  Optimization of constrained frequent set queri...   \n",
       "373228        1995           Temporal database system implementations   \n",
       "\n",
       "                                             right_authors  \\\n",
       "id                                                           \n",
       "5396296                                     Umeshwar Dayal   \n",
       "37056    Eugene Agichtein, Luis Gravano, Jeff Pavel, Vi...   \n",
       "4635259  Karthikeyan Ramasamy, Jignesh M. Patel, Jeffre...   \n",
       "4299157  Laks V. S. Lakshmanan, Raymond Ng, Jiawei Han,...   \n",
       "373228                              Michael H. B&#246;hlen   \n",
       "\n",
       "                                            right_venue  right_year  \n",
       "id                                                                   \n",
       "5396296                           Very Large Data Bases        1999  \n",
       "37056    International Conference on Management of Data        2001  \n",
       "4635259                           Very Large Data Bases        2000  \n",
       "4299157  International Conference on Management of Data        1999  \n",
       "373228                               ACM SIGMOD Record         1995  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "matches = pd.read_csv('Data/DBLP-ACM_perfectMapping.csv', encoding='cp1252')\n",
    "matching_tuples = [(m[0],m[1]) for m in matches.values]\n",
    "final_df_full = prod_df.copy()\n",
    "final_df_full.insert(0,'label',0)\n",
    "final_df_full['combined_index'] = list(zip(final_df_full.left_id, final_df_full.right_id))\n",
    "final_df_full.loc[final_df_full['combined_index'].isin(matching_tuples),'label'] = 1\n",
    "final_df_full = final_df_full.drop(columns=['combined_index','left_id','right_id'])\n",
    "final_df_full.index.name = 'id'\n",
    "final_df = final_df_full.sample(frac=0.05)\n",
    "display(final_df.head())\n",
    "display(final_df[final_df.label.eq(1)].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create train, validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,validate,test = np.split(final_df, [int(.6 * len(final_df)), int(.8 * len(final_df))])\n",
    "train_file = 'Data/train.csv'\n",
    "validate_file = 'Data/validate.csv'\n",
    "test_file = 'Data/test.csv'\n",
    "train.to_csv(train_file)\n",
    "validate.to_csv(validate_file)\n",
    "test.to_csv(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 432954,
     "status": "ok",
     "timestamp": 1599596979441,
     "user": {
      "displayName": "Zoé Goey",
      "photoUrl": "",
      "userId": "18241306402691044040"
     },
     "user_tz": -120
    },
    "id": "WJ37wi1HC9EJ",
    "outputId": "3d756959-d533-43e8-80c4-fab1738d7eee"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/p36workshop/lib/python3.6/site-packages/torchtext/data/field.py:150: UserWarning: MatchingField class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "\n",
      "Reading and processing data from \"./Data/train.csv\"\n",
      "/srv/conda/envs/p36workshop/lib/python3.6/site-packages/torchtext/data/example.py:68: UserWarning: Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.', UserWarning)\n",
      "/srv/conda/envs/p36workshop/lib/python3.6/site-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.', UserWarning)\n",
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Reading and processing data from \"./Data/validate.csv\"\n",
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Reading and processing data from \"./Data/test.csv\"\n",
      "0% [##############################] 100% | ETA: 00:00:00INFO:deepmatcher.data.field:Downloading vectors from https://drive.google.com/uc?export=download&id=1Vih8gAmgBnuYDxfblbT94P6WjB7s1ZSh\n",
      "wiki.en.bin: 8.49GB [02:23, 59.1MB/s]\n",
      "INFO:deepmatcher.data.field:Extracting vectors into /home/jovyan/.vector_cache\n",
      "/srv/conda/envs/p36workshop/lib/python3.6/site-packages/torchtext/data/iterator.py:48: UserWarning: MatchingIterator class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "\n",
      "Building vocabulary\n",
      "/srv/conda/envs/p36workshop/lib/python3.6/site-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:10\n",
      "\n",
      "Computing principal components\n",
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:02:24\n"
     ]
    }
   ],
   "source": [
    "train, validation, test = dm.data.process(\n",
    "    path='.',\n",
    "    left_prefix='left_',\n",
    "    right_prefix='right_',\n",
    "    label_attr='label',\n",
    "    id_attr='id',\n",
    "    cache=None,\n",
    "    train=train_file,\n",
    "    validation=validate_file,\n",
    "    test=test_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4RCEIm8MQJO3"
   },
   "source": [
    "#### Peeking at processed data\n",
    "Let's take a look at how the processed data looks like. To do this, we get the raw `pandas` table corresponding to the processed training dataset object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 554,
     "status": "ok",
     "timestamp": 1599597483621,
     "user": {
      "displayName": "Zoé Goey",
      "photoUrl": "",
      "userId": "18241306402691044040"
     },
     "user_tz": -120
    },
    "id": "qmkzAzWOQJO3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>left_title</th>\n",
       "      <th>left_authors</th>\n",
       "      <th>left_venue</th>\n",
       "      <th>left_year</th>\n",
       "      <th>right_title</th>\n",
       "      <th>right_authors</th>\n",
       "      <th>right_venue</th>\n",
       "      <th>right_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1046262</td>\n",
       "      <td>0</td>\n",
       "      <td>spatial joins using r-trees : breadth-first tr...</td>\n",
       "      <td>ning jing , yun-wu huang , elke a. rundensteiner</td>\n",
       "      <td>vldb</td>\n",
       "      <td>1997</td>\n",
       "      <td>mind your vocabulary : query mapping across he...</td>\n",
       "      <td>chen-chuan k. chang , h &amp; # 233 ; ctor garc &amp; ...</td>\n",
       "      <td>international conference on management of data</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>723207</td>\n",
       "      <td>0</td>\n",
       "      <td>declarative data cleaning : language , model ,...</td>\n",
       "      <td>daniela florescu , cristian-augustin saita , e...</td>\n",
       "      <td>vldb</td>\n",
       "      <td>2001</td>\n",
       "      <td>transactional information systems : theory , a...</td>\n",
       "      <td>marc h. scholl</td>\n",
       "      <td>acm sigmod record</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2621978</td>\n",
       "      <td>0</td>\n",
       "      <td>on-line warehouse view maintenance</td>\n",
       "      <td>jennifer widom , dallan quass</td>\n",
       "      <td>sigmod conference</td>\n",
       "      <td>1997</td>\n",
       "      <td>p-grid : a self-organizing structured p2p system</td>\n",
       "      <td>karl aberer , philippe cudr &amp; # 233 ; -mauroux...</td>\n",
       "      <td>acm sigmod record</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3330295</td>\n",
       "      <td>0</td>\n",
       "      <td>querying and mining data streams : you only ge...</td>\n",
       "      <td>minos n. garofalakis , rajeev rastogi , johann...</td>\n",
       "      <td>sigmod conference</td>\n",
       "      <td>2002</td>\n",
       "      <td>comprehension syntax</td>\n",
       "      <td>peter buneman , leonid libkin , dan suciu , va...</td>\n",
       "      <td>acm sigmod record</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3254369</td>\n",
       "      <td>0</td>\n",
       "      <td>on parallel execution of multiple pipelined ha...</td>\n",
       "      <td>philip s. yu , hui-i hsiao , ming-syan chen</td>\n",
       "      <td>sigmod conference</td>\n",
       "      <td>1994</td>\n",
       "      <td>bypassing joins in disjunctive queries</td>\n",
       "      <td>michael steinbrunn , klaus peithner , guido mo...</td>\n",
       "      <td>very large data bases</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  label                                         left_title  \\\n",
       "0  1046262      0  spatial joins using r-trees : breadth-first tr...   \n",
       "1   723207      0  declarative data cleaning : language , model ,...   \n",
       "2  2621978      0                 on-line warehouse view maintenance   \n",
       "3  3330295      0  querying and mining data streams : you only ge...   \n",
       "4  3254369      0  on parallel execution of multiple pipelined ha...   \n",
       "\n",
       "                                        left_authors         left_venue  \\\n",
       "0   ning jing , yun-wu huang , elke a. rundensteiner               vldb   \n",
       "1  daniela florescu , cristian-augustin saita , e...               vldb   \n",
       "2                      jennifer widom , dallan quass  sigmod conference   \n",
       "3  minos n. garofalakis , rajeev rastogi , johann...  sigmod conference   \n",
       "4        philip s. yu , hui-i hsiao , ming-syan chen  sigmod conference   \n",
       "\n",
       "  left_year                                        right_title  \\\n",
       "0      1997  mind your vocabulary : query mapping across he...   \n",
       "1      2001  transactional information systems : theory , a...   \n",
       "2      1997   p-grid : a self-organizing structured p2p system   \n",
       "3      2002                               comprehension syntax   \n",
       "4      1994             bypassing joins in disjunctive queries   \n",
       "\n",
       "                                       right_authors  \\\n",
       "0  chen-chuan k. chang , h & # 233 ; ctor garc & ...   \n",
       "1                                     marc h. scholl   \n",
       "2  karl aberer , philippe cudr & # 233 ; -mauroux...   \n",
       "3  peter buneman , leonid libkin , dan suciu , va...   \n",
       "4  michael steinbrunn , klaus peithner , guido mo...   \n",
       "\n",
       "                                      right_venue right_year  \n",
       "0  international conference on management of data       1999  \n",
       "1                               acm sigmod record       2001  \n",
       "2                               acm sigmod record       2003  \n",
       "3                               acm sigmod record       1994  \n",
       "4                           very large data bases       1995  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_table = train.get_raw_table()\n",
    "train_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8mr3oVzuQJO6"
   },
   "source": [
    "## Define neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 502,
     "status": "ok",
     "timestamp": 1599597518172,
     "user": {
      "displayName": "Zoé Goey",
      "photoUrl": "",
      "userId": "18241306402691044040"
     },
     "user_tz": -120
    },
    "id": "NwUE2jMXQJO7"
   },
   "outputs": [],
   "source": [
    "model = dm.MatchingModel(attr_summarizer='hybrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7iLAHpuVQJO9"
   },
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 103904,
     "status": "ok",
     "timestamp": 1599597625013,
     "user": {
      "displayName": "Zoé Goey",
      "photoUrl": "",
      "userId": "18241306402691044040"
     },
     "user_tz": -120
    },
    "id": "RIZclsK1QJO-",
    "outputId": "ab07d044-af55-4b1b-ac70-706f33e4f878"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/p36workshop/lib/python3.6/site-packages/torchtext/data/iterator.py:48: UserWarning: MatchingIterator class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "/srv/conda/envs/p36workshop/lib/python3.6/site-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Number of trainable parameters: 9210006\n",
      "===>  TRAIN Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/p36workshop/lib/python3.6/site-packages/torch/nn/functional.py:2352: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:26:43\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 1 || Run Time: 1289.5 | Load Time:  314.4 || F1:  36.62 | Prec:  27.27 | Rec:  55.71 || Ex/s: 112.25\n",
      "\n",
      "===>  EVAL Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:05:11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 1 || Run Time:  206.0 | Load Time:  105.8 || F1:  60.61 | Prec:  44.44 | Rec:  95.24 || Ex/s: 192.44\n",
      "\n",
      "* Best F1: tensor(60.6061, device='cuda:0')\n",
      "Saving best model...\n",
      "Done.\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:26:47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 2 || Run Time: 1292.0 | Load Time:  315.5 || F1:  64.58 | Prec:  50.82 | Rec:  88.57 || Ex/s: 112.00\n",
      "\n",
      "===>  EVAL Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:05:16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 2 || Run Time:  210.1 | Load Time:  106.2 || F1:  60.00 | Prec: 100.00 | Rec:  42.86 || Ex/s: 189.71\n",
      "\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:26:44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 3 || Run Time: 1290.3 | Load Time:  314.8 || F1:  84.28 | Prec:  75.28 | Rec:  95.71 || Ex/s: 112.16\n",
      "\n",
      "===>  EVAL Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:05:11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 3 || Run Time:  205.9 | Load Time:  106.0 || F1:  89.47 | Prec: 100.00 | Rec:  80.95 || Ex/s: 192.43\n",
      "\n",
      "* Best F1: tensor(89.4737, device='cuda:0')\n",
      "Saving best model...\n",
      "Done.\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:26:45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 4 || Run Time: 1291.2 | Load Time:  315.0 || F1:  84.47 | Prec:  74.73 | Rec:  97.14 || Ex/s: 112.09\n",
      "\n",
      "===>  EVAL Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:05:11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 4 || Run Time:  206.3 | Load Time:  105.5 || F1:  83.72 | Prec:  81.82 | Rec:  85.71 || Ex/s: 192.48\n",
      "\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:26:40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 5 || Run Time: 1286.7 | Load Time:  314.2 || F1:  92.00 | Prec:  86.25 | Rec:  98.57 || Ex/s: 112.46\n",
      "\n",
      "===>  EVAL Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:05:11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 5 || Run Time:  206.2 | Load Time:  105.9 || F1:  92.31 | Prec: 100.00 | Rec:  85.71 || Ex/s: 192.31\n",
      "\n",
      "* Best F1: tensor(92.3077, device='cuda:0')\n",
      "Saving best model...\n",
      "Done.\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:26:42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 6 || Run Time: 1288.9 | Load Time:  314.4 || F1:  93.06 | Prec:  90.54 | Rec:  95.71 || Ex/s: 112.28\n",
      "\n",
      "===>  EVAL Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:05:13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 6 || Run Time:  207.6 | Load Time:  106.1 || F1:  90.00 | Prec:  94.74 | Rec:  85.71 || Ex/s: 191.27\n",
      "\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:26:47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 7 || Run Time: 1293.0 | Load Time:  315.1 || F1:  97.18 | Prec:  95.83 | Rec:  98.57 || Ex/s: 111.95\n",
      "\n",
      "===>  EVAL Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:05:12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 7 || Run Time:  206.8 | Load Time:  106.1 || F1:  90.00 | Prec:  94.74 | Rec:  85.71 || Ex/s: 191.81\n",
      "\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:26:47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 8 || Run Time: 1293.0 | Load Time:  315.1 || F1:  98.57 | Prec:  98.57 | Rec:  98.57 || Ex/s: 111.95\n",
      "\n",
      "===>  EVAL Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:05:13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 8 || Run Time:  207.8 | Load Time:  106.2 || F1:  90.00 | Prec:  94.74 | Rec:  85.71 || Ex/s: 191.10\n",
      "\n",
      "---------------------\n",
      "\n",
      "Loading best model...\n",
      "Training done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(92.3077, device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.run_train(\n",
    "    train,\n",
    "    validation,\n",
    "    epochs=8,\n",
    "    batch_size=16,\n",
    "    best_save_path='Results/model_dblp_acm.pth',\n",
    "    pos_neg_ratio=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lejVqpjAQJPD"
   },
   "source": [
    "## Model evaluation\n",
    "\n",
    "Now that we have a trained model for entity matching, we can now evaluate its accuracy on test data, to estimate the performance of the model on unlabeled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1589,
     "status": "ok",
     "timestamp": 1599598867340,
     "user": {
      "displayName": "Zoé Goey",
      "photoUrl": "",
      "userId": "18241306402691044040"
     },
     "user_tz": -120
    },
    "id": "jLoneAI_QJPD",
    "outputId": "d9700965-03dc-438c-fc7f-ccb7bd9083a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===>  EVAL Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:03:55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 5 || Run Time:  116.7 | Load Time:  118.8 || F1:  87.80 | Prec:  85.71 | Rec:  90.00 || Ex/s: 254.81\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(87.8049, device='cuda:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute F1 on test set\n",
    "model.run_eval(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python record linkage toolkit\n",
    "\n",
    "We will now see how the methods from the Python record linkage toolkit compare to the DeepMatcher approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 610,
     "status": "ok",
     "timestamp": 1599598907592,
     "user": {
      "displayName": "Zoé Goey",
      "photoUrl": "",
      "userId": "18241306402691044040"
     },
     "user_tz": -120
    },
    "id": "42xDP-GUYD9B",
    "outputId": "8dc47cf4-3142-44ca-fc45-68bbbd72b07c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compare>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comparison step\n",
    "compare_cl = recordlinkage.Compare()\n",
    "compare_cl.string('title', 'title', method='jarowinkler', threshold=0.85,label = 'title')\n",
    "compare_cl.string('authors', 'authors', method='jarowinkler', threshold=0.85,label = 'authors')\n",
    "compare_cl.exact('year', 'year', label='year')\n",
    "compare_cl.string('venue', 'venue', method='jarowinkler', threshold=0.65,label = 'authors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 543,
     "status": "ok",
     "timestamp": 1599599445772,
     "user": {
      "displayName": "Zoé Goey",
      "photoUrl": "",
      "userId": "18241306402691044040"
     },
     "user_tz": -120
    },
    "id": "rjKDqopqYD9D"
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "true_links = {}\n",
    "features = {}\n",
    "validation = {}\n",
    "datasets= {'train': train_file, \n",
    "'test': test_file,\n",
    "'validation': validate_file}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 656,
     "status": "ok",
     "timestamp": 1599599447606,
     "user": {
      "displayName": "Zoé Goey",
      "photoUrl": "",
      "userId": "18241306402691044040"
     },
     "user_tz": -120
    },
    "id": "f0ej2gBJYD9G"
   },
   "outputs": [],
   "source": [
    "# Some helper functions\n",
    "def print_results(name, table):\n",
    "    print(\"\".join(['*' for x in range(len(name) + 1)]))\n",
    "    print('{}'.format(name))\n",
    "    print(\"\".join(['*' for x in range(len(name) + 1)]))\n",
    "    print(\"Confusion matrix:\")\n",
    "    print(table['confusion_matrix'])\n",
    "    print(\"Accuracy: {}\".format(table['accuracy']))\n",
    "    print(\"Recall: {}\".format(table['recall']))\n",
    "    print(\"F-score: {}\".format(table['f-score']))\n",
    "    print('\\n')\n",
    "    \n",
    "def performance_metrics(true_links, result, set_size):\n",
    "    validation = {}\n",
    "    validation['confusion_matrix'] = recordlinkage.confusion_matrix(true_links, result, set_size)\n",
    "    validation['accuracy'] = recordlinkage.accuracy(true_links, result, len(features['validation']))\n",
    "    validation['recall'] = recordlinkage.recall(true_links, result)\n",
    "    validation['f-score'] = recordlinkage.fscore(true_links, result)\n",
    "    return validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 566,
     "status": "ok",
     "timestamp": 1599599449652,
     "user": {
      "displayName": "Zoé Goey",
      "photoUrl": "",
      "userId": "18241306402691044040"
     },
     "user_tz": -120
    },
    "id": "oQ9HNmU0YD9I"
   },
   "outputs": [],
   "source": [
    "# Train and validate various classifiers\n",
    "classifiers= {\n",
    "'Hand-tuned':None,\n",
    "'Logistic regression':recordlinkage.LogisticRegressionClassifier(),\n",
    "'Naive Bayes': recordlinkage.NaiveBayesClassifier(),\n",
    "'Support vector machine': recordlinkage.SVMClassifier(),\n",
    "'K-means': recordlinkage.KMeansClassifier(),\n",
    "'ECM': recordlinkage.ECMClassifier()}\n",
    "for key in datasets:\n",
    "    df = pd.read_csv(datasets[key])\n",
    "    nof_cols = int((df.shape[1] - 2)/2)\n",
    "    dfA = df.iloc[:,2:nof_cols + 2]\n",
    "    dfB = df.iloc[:,nof_cols + 2:df.shape[1]]\n",
    "    dfA.rename(columns={c:c[5:] for c in dfA.columns },inplace=True)\n",
    "    dfB.rename(columns={c:c[6:] for c in dfB.columns },inplace=True)\n",
    "\n",
    "    tuples = [(i,i) for i in range(len(df)) if df.iloc[i]['label'] == 1]\n",
    "    true_links[key] = pd.MultiIndex.from_tuples(tuples)\n",
    "\n",
    "    tuples_full = [(i,i) for i in range(len(df))]\n",
    "    candidate_links = pd.MultiIndex.from_tuples(tuples_full)\n",
    "    # Final features (used in other methods as well)\n",
    "    features[key] = compare_cl.compute(candidate_links, dfA, dfB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 748,
     "status": "ok",
     "timestamp": 1599599452122,
     "user": {
      "displayName": "Zoé Goey",
      "photoUrl": "",
      "userId": "18241306402691044040"
     },
     "user_tz": -120
    },
    "id": "qPKWiwXwYD9L",
    "outputId": "69e4cc03-56d1-4ae0-d131-c99542886a38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********\n",
      "Hand-tuned\n",
      "***********\n",
      "Confusion matrix:\n",
      "[[   21     0]\n",
      " [10593 49397]]\n",
      "Accuracy: 0.823482361567046\n",
      "Recall: 1.0\n",
      "F-score: 0.003949224259520451\n",
      "\n",
      "\n",
      "********************\n",
      "Logistic regression\n",
      "********************\n",
      "Confusion matrix:\n",
      "[[   20     1]\n",
      " [    0 59990]]\n",
      "Accuracy: 0.9999833363883288\n",
      "Recall: 0.9523809523809523\n",
      "F-score: 0.975609756097561\n",
      "\n",
      "\n",
      "************\n",
      "Naive Bayes\n",
      "************\n",
      "Confusion matrix:\n",
      "[[   20     1]\n",
      " [    0 59990]]\n",
      "Accuracy: 0.9999833363883288\n",
      "Recall: 0.9523809523809523\n",
      "F-score: 0.975609756097561\n",
      "\n",
      "\n",
      "***********************\n",
      "Support vector machine\n",
      "***********************\n",
      "Confusion matrix:\n",
      "[[   20     1]\n",
      " [    0 59990]]\n",
      "Accuracy: 0.9999833363883288\n",
      "Recall: 0.9523809523809523\n",
      "F-score: 0.975609756097561\n",
      "\n",
      "\n",
      "********\n",
      "K-means\n",
      "********\n",
      "Confusion matrix:\n",
      "[[    7    14]\n",
      " [  564 59426]]\n",
      "Accuracy: 0.99036843245405\n",
      "Recall: 0.3333333333333333\n",
      "F-score: 0.02364864864864865\n",
      "\n",
      "\n",
      "****\n",
      "ECM\n",
      "****\n",
      "Confusion matrix:\n",
      "[[   20     1]\n",
      " [    2 59988]]\n",
      "Accuracy: 0.9999500091649864\n",
      "Recall: 0.9523809523809523\n",
      "F-score: 0.9302325581395349\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key in classifiers:\n",
    "    validation[key] = {}\n",
    "    if key == 'Hand-tuned':\n",
    "        # Immediate prediction\n",
    "        result = features['validation'][features['validation'].sum(axis=1) > 0].index\n",
    "    else:\n",
    "        # Training \n",
    "        if key == 'ECM':\n",
    "            classifiers[key].fit(features['train']) # somehow ECM cannot ignore redundant argument, opposed to K-Means\n",
    "        else:\n",
    "            classifiers[key].fit(features['train'], true_links['train'])\n",
    "        # Predict the match status for all test record pairs\n",
    "        result =  classifiers[key].predict(features['validation'])\n",
    "        \n",
    "    # Validate\n",
    "    validation[key] = performance_metrics(true_links['validation'], result, len(features['validation']))\n",
    "    \n",
    "    #Print results\n",
    "    print_results(key, validation[key])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 550,
     "status": "ok",
     "timestamp": 1599599467005,
     "user": {
      "displayName": "Zoé Goey",
      "photoUrl": "",
      "userId": "18241306402691044040"
     },
     "user_tz": -120
    },
    "id": "xC2Z4DahYD9P",
    "outputId": "698dd539-4a93-40cb-9280-ca32b315a8db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************************************\n",
      "Selected model (Logistic regression) on test set\n",
      "*************************************************\n",
      "Confusion matrix:\n",
      "[[   19     1]\n",
      " [    2 59989]]\n",
      "Accuracy: 0.9999500091649864\n",
      "Recall: 0.95\n",
      "F-score: 0.9268292682926829\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test results for best method\n",
    "f_scores = {key:validation[key]['f-score'] for key in validation}\n",
    "best_model = max(f_scores, key = f_scores.get) \n",
    "if best_model == 'Hand-tuned':\n",
    "    result = features['test'][features['test'].sum(axis=1) > 2].index\n",
    "else:\n",
    "    result = classifiers[best_model].predict(features['test'])\n",
    "test =  performance_metrics(true_links['test'], result, len(features['test']))\n",
    "print_results(\"Selected model ({}) on test set\".format(best_model), test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "EntityMatchingAmazon.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
